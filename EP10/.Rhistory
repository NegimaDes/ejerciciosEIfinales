knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso")
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
prueba <- rbind(pruebaA, pruebaB)
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado2)
summary(mejorado)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso")
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
prueba <- rbind(pruebaA, pruebaB)
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado)
summary(mejorado)
summary(completo)
plot(mejorado, which = 2)
View(entrenamiento)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso")
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
entrenamiento <- entrenamiento[sample(nrow(entrenamiento)), ]
prueba <- rbind(pruebaA, pruebaB)
prueba <- prueba[sample(nrow(prueba)), ]
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
# modelo con predictores seleccionados por p-value
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado)
# Multicolinealidad
vifs <- vif(mejorado)
library(dplyr)
library(ggplot2)
library(car)
# Multicolinealidad
vifs <- vif(mejorado)
vifs
mean(vifs)
durbinWatsonTest(mejorado, max.lag = 5)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso")
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
entrenamiento <- entrenamiento[sample(nrow(entrenamiento)), ]
prueba <- rbind(pruebaA, pruebaB)
prueba <- prueba[sample(nrow(prueba)), ]
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
# modelo con predictores seleccionados por p-value
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado)
# Multicolinealidad
vifs <- vif(mejorado)
vifs
mean(vifs)
########________________________
library(rms)
anova(mejorado, test = "LRT")
########________________________
# Independencia de los residuos
durbinWatsonTest(mejorado, max.lag = 5)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso")
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
entrenamiento <- entrenamiento[sample(nrow(entrenamiento)), ]
prueba <- rbind(pruebaA, pruebaB)
prueba <- prueba[sample(nrow(prueba)), ]
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
# modelo con predictores seleccionados por p-value
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado)
# Multicolinealidad
vifs <- vif(mejorado)
vifs
mean(vifs)
########________________________
anova(mejorado, test = "LRT")
########________________________
# Independencia de los residuos
durbinWatsonTest(mejorado, max.lag = 5)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(car)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso")
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
entrenamiento <- entrenamiento[sample(nrow(entrenamiento)), ]
prueba <- rbind(pruebaA, pruebaB)
prueba <- prueba[sample(nrow(prueba)), ]
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
# modelo con predictores seleccionados por p-value
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado)
# Multicolinealidad
vifs <- vif(mejorado)
vifs
mean(vifs)
########________________________
anova(mejorado, test = "LRT")
########________________________
# Independencia de los residuos
durbinWatsonTest(mejorado, max.lag = 5)
durbinWatsonTest(mejorado, max.lag = 5)
durbinWatsonTest(mejorado, max.lag = 1)
