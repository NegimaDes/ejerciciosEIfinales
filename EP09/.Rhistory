summary(modMejorado)
plot(modMejorado)
p <- ggscatter(muestra, x = c("Navel.Girth", "Calf.Maximum.Girth", "Wrist.Minimum.Girth", "Shoulder.Girth", "Chest.diameter"), y = "Weight", color = "blue", fill = "blue")
completo <- lm(Weight ~ Navel.Girth + Calf.Maximum.Girth + Age + Chest.diameter + Elbows.diameter + Shoulder.Girth + Chest.Girth + Bitrochanteric.diameter + Wrist.Minimum.Girth, data = muestra)
summary(completo)
add1(modelo, scope = completo)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
summary(modMejorado)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
plot(modMejorado)
add1(modelo, scope = completo)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
plot(modMejorado)
add1(modMejorado, scope = completo)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
plot(modMejorado)
shapiro.test(modMejorado$residuals)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
plot(modMejorado)
shapiro.test(modelo$residuals)
modMejorado <- update(modelo, . ~ . Shoulder.Girth + Chest.diameter)
modMejorado <- update(modelo, . ~ . + Shoulder.Girth + Chest.diameter)
shapiro.test(modelo$residuals)
Shoulder.Girth
shapiro.test(modMejorado$residuals)
plot(modMejorado)
add1(modMejorado, scope = completo)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
summary(modMejorado)
shapiro.test(modMejorado$residuals)
summary(modMejorado)
plot(modMejorado)
library(dplyr)
library(ggpubr)
datos <- read.csv2("EP09 Datos.csv")
head(datos)
mujeres <- filter(datos, Gender == 0)
set.seed(1624)
muestra <- mujeres[sample(nrow(mujeres), 50), ]
predictores <- sample(24, 8)
predictores
muestraP <- muestra[predictores]
head(muestraP)
modelo <- lm(Weight ~ Navel.Girth, data = muestra)
p <- ggscatter(muestra, x = "Navel.Girth", y = "Weight", color = "blue", fill = "blue")
p <- p + geom_smooth(method = lm, se = FALSE, colour = "red")
p
summary(modelo)
plot(modelo)
completo <- lm(Weight ~ Navel.Girth + Calf.Maximum.Girth + Age + Chest.diameter + Elbows.diameter + Shoulder.Girth + Chest.Girth + Bitrochanteric.diameter + Wrist.Minimum.Girth, data = muestra)
summary(completo)
add1(modelo, scope = completo)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
shapiro.test(modMejorado$residuals)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
plot(modMejorado)
shapiro.test(modMejorado$residuals)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
add1(modelo, scope = completo)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
plot(modMejorado)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth + Chest.diameter)
shapiro.test(modMejorado$residuals)
plot(modMejorado)
add1(modelo, scope = completo)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth)
add1(modMejorado, scope = completo)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth + Shoulder.Girth)
add1(modMejorado, scope = completo)
shapiro.test(modMejorado$residuals)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth)
shapiro.test(modMejorado$residuals)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
library(dplyr)
library(ggpubr)
datos <- read.csv2("EP09 Datos.csv")
head(datos)
mujeres <- filter(datos, Gender == 0)
set.seed(1624)
muestra <- mujeres[sample(nrow(mujeres), 50), ]
predictores <- sample(24, 8)
predictores
muestraP <- muestra[predictores]
head(muestraP)
modelo <- lm(Weight ~ Navel.Girth, data = muestra)
p <- ggscatter(muestra, x = "Navel.Girth", y = "Weight", color = "blue", fill = "blue")
p <- p + geom_smooth(method = lm, se = FALSE, colour = "red")
p
summary(modelo)
plot(modelo)
completo <- lm(Weight ~ Navel.Girth + Calf.Maximum.Girth + Age + Chest.diameter + Elbows.diameter + Shoulder.Girth + Chest.Girth + Bitrochanteric.diameter + Wrist.Minimum.Girth, data = muestra)
summary(completo)
modMejorado <- update(modelo, . ~ . + Wrist.Minimum.Girth)
shapiro.test(modMejorado$residuals)
modMejorado <- update(modelo, . ~ . + Calf.Maximum.Girth)
shapiro.test(modMejorado$residuals)
shapiro.test(modelo$residuals)
# Importar librerias
library(dplyr)
library(pROC)
# Se leen los datos
datos <- read.csv2("EP09 Datos.csv")
# Se verifica que los datos se leen correctamente
head(datos)
# Se crea una nueva columna para calcular el IMC
datos[["IMC"]] <- datos[["Weight"]]/((datos[["Height"]])/100)^2
# Se crea una nueva columna para determinar si está con sobrepeso o no
# según el IMC.
datos[["EN"]] <- ifelse(datos[["IMC"]] >= 25, 1, 0)
# Se verifica que se hayan agregado correctamente las columnas
head(datos)
datos <- datos %>% mutate(index = row_number())
# Se verifica que se hayan agregado correctamente las columnas
head(datos)
# Ahora podemos construir un modelo de regresión logística para predecir la
# variable EN, de acuerdo con las siguientes instrucciones:
# 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro
# dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor
# edad del equipo.
set.seed(5547)
# Se filtran los datos para tener solo hombres
hombres <- datos[datos$Gender == 1, ]
# Se saca una muestra de 45 hombres que tengan sobrepeso
sobrepeso <- hombres %>% filter(EN == 1) %>% sample_n(45)
# Se saca una muestra de 45 hombres que no tengan sobrepeso
nosobrepeso <- hombres %>% filter(EN == 0) %>% sample_n(45)
# Se unen las dos muestras
muestra <- rbind(sobrepeso, nosobrepeso)
# Se unen las muestras donde se extraen 30 hombres con sobrepeso
# y 30 hombres sin sobrepeso
set_construccion <- rbind(
sample_n(muestra %>% filter(EN == 1), 30),
sample_n(muestra %>% filter(EN == 0), 30)
)
# Se saca la muestra restante tomando a la "muestra global" y a la
# submuestra, restándose
set_evaluacion <- setdiff(muestra, set_construccion)
# Primer modelo
modelo_logistico <- glm(EN ~ Navel.Girth,
family = binomial(link = "logit"), data = set_construccion)
modeloTest <- add1(modelo_logistico, scope = .~. + Bitrochanteric.diameter + Elbows.diameter +
Wrists.diameter + Knees.diameter + Waist.Girth + Hip.Girth + Knee.Girth + Ankle.Minimum.Girth)
modeloTest
desviacion <- -2*logLik(modelo_logistico)
cat("La desviación es de: ", desviacion)
# k = número de predictores
# n = tamaño de muestra
k <- length(coef(modelo_logistico))
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
# Resumen del modelo
summary(modelo_logistico)
# 6. Usando herramientas estándares1 para la exploración de modelos del entorno
# R, buscar entre dos y cinco predictores de entre las variables seleccionadas
# al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
modelo_logistico_2 <- update(modelo_logistico, .~. + Waist.Girth)
summary(modeloTest)
modeloTest
# 6. Usando herramientas estándares1 para la exploración de modelos del entorno
# R, buscar entre dos y cinco predictores de entre las variables seleccionadas
# al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
modelo_logistico_2 <- update(modelo_logistico, .~. + Waist.Girth)
desviacion <- -2*logLik(modelo_logistico_2)
cat("La desviación es de: ", desviacion)
# k = número de predictores
# n = tamaño de muestra
k <- length(coef(modelo_logistico_2))
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
modeloTest <- add1(modelo_logistico_2, scope = .~. + Bitrochanteric.diameter + Elbows.diameter +
Wrists.diameter + Knees.diameter + Hip.Girth + Knee.Girth + Ankle.Minimum.Girth)
modeloTest
modelo_logistico_3 <- update(modelo_logistico_2, .~. + Bitrochanteric.diameter)
desviacion <- -2*logLik(modelo_logistico_3)
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
modeloTest <- add1(modelo_logistico_3, scope = .~. + Elbows.diameter +
Wrists.diameter + Knees.diameter + Hip.Girth + Knee.Girth + Ankle.Minimum.Girth)
modeloTest
# 7. Evaluar la confiabilidad de los modelos (i.e. que tengan un buen nivel de
# ajuste y son generalizables) y “arreglarlos” en caso de que tengan algún problema.
desviacion <- -2*logLik(modelo_logistico_3)
cat("La desviación es de: ", desviacion)
# k = número de predictores
# n = tamaño de muestra
k <- length(coef(modelo_logistico_3))
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
cat("Evaluación del modelo a partir del conjunto de entrenamiento:\n")
probs_e <- predict(modelo_logistico_3, set_evaluacion, type = "response")
umbral <- 0.5
preds_e <- ifelse(probs_e > umbral, 1, 0)
ROC_e <- roc(set_evaluacion[["EN"]], probs_e)
plot(ROC_e)
matriz_confusion <- table(Predicciones = preds_e, Real = set_evaluacion$EN)
sensibilidad <- matriz_confusion[2, 2] / sum(matriz_confusion[2, ])
especificidad <- matriz_confusion[1, 1] / sum(matriz_confusion[1, ])
print(paste("Sensibilidad:", sensibilidad))
print(paste("Especificidad:", especificidad))
cat("Evaluación del modelo con el conjunto de prueba:\n")
probs_p <- predict(modelo_logistico_3, set_construccion, type = "response")
umbral <- 0.5
preds_p <- ifelse(probs_p > umbral, 1, 0)
ROC_p <- roc(set_construccion[["EN"]], probs_p)
plot(ROC_p)
matriz_confusion <- table(Predicciones = preds_p, Real = set_construccion$EN)
sensibilidad <- matriz_confusion[2, 2] / sum(matriz_confusion[2, ])
especificidad <- matriz_confusion[1, 1] / sum(matriz_confusion[1, ])
print(paste("Sensibilidad:", sensibilidad))
print(paste("Especificidad:", especificidad))
datos_disponibles <- datos %>%
anti_join(set_construccion, by = "index") %>%
anti_join(set_evaluacion, by = "index")
set_nuevo <- sample_n(datos_disponibles, 40)
cat("Evaluación del modelo con el conjunto de 40 personas:\n")
probs_personas <- predict(modelo_logistico_3, set_nuevo, type = "response")
umbral <- 0.5
preds_personas <- ifelse(probs_personas > umbral, 1, 0)
ROC_personas <- roc(set_nuevo[["EN"]], probs_personas)
plot(ROC_personas)
matriz_confusion <- table(Predicciones = preds_personas, Real = set_nuevo$EN)
sensibilidad <- matriz_confusion[2, 2] / sum(matriz_confusion[2, ])
especificidad <- matriz_confusion[1, 1] / sum(matriz_confusion[1, ])
print(paste("Sensibilidad:", sensibilidad))
print(paste("Especificidad:", especificidad))
library("tidyverse")
library("ggpubr")
library("car")
library ("pROC")
datos <- read.csv2("EP09 Datos.csv", sep= ";")
set.seed(1665)
#Se preparan los datos
datos <- datos %>% filter(Gender == 1)
index <- 1:nrow(datos)
datos <- datos %>% mutate(index, imc = as.numeric(datos$Weight) / (as.numeric(datos$Height)/100)**2)
datos <- datos %>% mutate(index, EN = case_when( datos$imc  >= 25 ~ as.numeric(1), datos$imc < 25 ~ as.numeric(0)))
#Se separan los grupos por sobrepeso y no sobrepeso
sobrepeso <- datos %>% filter(EN == 1)
no_sobrepeso <- datos %>% filter(EN == 0)
index_sample_sobrepeso <- sample.int(n=nrow(sobrepeso) , size=45, replace=FALSE)
index_sample_no_sobrepeso <- sample.int(n=nrow(no_sobrepeso) , size=45, replace=FALSE)
sample_sobrepeso <- sobrepeso[index_sample_sobrepeso, ]
sample_no_sobrepeso <- no_sobrepeso[index_sample_no_sobrepeso, ]
index_mitad_sobrepeso <- sample.int(n=nrow(sample_sobrepeso) , size=30, replace=FALSE)
index_mitad_no_sobrepeso <- sample.int(n=nrow(sample_no_sobrepeso) , size=30, replace=FALSE)
# Se obtiene la muestra de entrenamiento para la generación del modelo
entrenamiento <- sample_sobrepeso[index_mitad_sobrepeso, ]
entrenamiento <- rbind(entrenamiento, sample_no_sobrepeso[index_mitad_no_sobrepeso, ])
entrenamiento <- sample_n(entrenamiento, 60, replace = FALSE)
# Se obtiene la muestra de prueba para evaluar la generabilidad del modelo.
prueba <- sample_sobrepeso[-index_mitad_sobrepeso, ]
prueba <- rbind(prueba, sample_no_sobrepeso[-index_mitad_no_sobrepeso, ])
prueba <- sample_n(prueba, 30, replace = FALSE)
modelo <- glm(EN ~ Navel.Girth, family = binomial(link = "logit"), data = entrenamiento)
print(summary(modelo))
# Se Prueba agregar una de las 8 variables escogidas previamente
modelotest <- add1(modelo, scope = .~. + Age + Chest.Girth + Biiliac.diameter +
Calf.Maximum.Girth + Bicep.Girth + Bitrochanteric.diameter +
Ankles.diameter + Knee.Girth)
print(modelotest)
modelo <- update(modelo, .~. + Calf.Maximum.Girth)
print(summary(modelo))
modelotest <- add1(modelo, scope = .~. + Age + Chest.Girth + Biiliac.diameter + Bicep.Girth + Bitrochanteric.diameter +
Ankles.diameter + Knee.Girth)
print(modelotest)
modelo <- update(modelo, .~. + Chest.Girth)
print(summary(modelo))
modelotest <- add1(modelo, scope = .~. + Age + Biiliac.diameter + Bicep.Girth + Bitrochanteric.diameter +
Ankles.diameter + Knee.Girth)
print(modelotest)
modelo <- update(modelo, .~. + Age)
print(summary(modelo))
modelotest <- add1(modelo, scope = .~. + Biiliac.diameter + Bicep.Girth + Bitrochanteric.diameter +
Ankles.diameter + Knee.Girth)
print(modelotest)
# Verificación de Condiciones:
#1. Se verifica la colinealidad y tolerancia del modelo.
VIF <- vif(modelo)
print(VIF)
print(1/VIF)
#2. Se verifica
durbinWatsonTest(modelo , max.lag = 5)
#3. Se verifica que las variables predictoras tengan una relación lineal}
# con la variable de respuesta.
print(summary(modelo))
# Se evalúa el modelo con el conjunto de prueba
probs_e <- predict(modelo, prueba, type = "response")
preds_e <- sapply(probs_e , function(p)ifelse (p >= 0.5, "1","0"))
# Se leen los datos
datos <- read.csv2("EP09 Datos.csv")
# Se verifica que los datos se leen correctamente
head(datos)
# Se crea una nueva columna para calcular el IMC
datos[["IMC"]] <- datos[["Weight"]]/((datos[["Height"]])/100)^2
# Se crea una nueva columna para determinar si está con sobrepeso o no
# según el IMC.
datos[["EN"]] <- ifelse(datos[["IMC"]] >= 25, 1, 0)
# Se verifica que se hayan agregado correctamente las columnas
head(datos)
datos <- datos %>% mutate(index = row_number())
# Ahora podemos construir un modelo de regresión logística para predecir la
# variable EN, de acuerdo con las siguientes instrucciones:
# 1. Definir la semilla a utilizar, que corresponde a los últimos cuatro
# dígitos del RUN (sin considerar el dígito verificador) del integrante de mayor
# edad del equipo.
set.seed(5547)
# Se filtran los datos para tener solo hombres
hombres <- datos[datos$Gender == 1, ]
# Se saca una muestra de 45 hombres que tengan sobrepeso
sobrepeso <- hombres %>% filter(EN == 1) %>% sample_n(45)
# Se saca una muestra de 45 hombres que no tengan sobrepeso
nosobrepeso <- hombres %>% filter(EN == 0) %>% sample_n(45)
# Se unen las dos muestras
muestra <- rbind(sobrepeso, nosobrepeso)
# Se unen las muestras donde se extraen 30 hombres con sobrepeso
# y 30 hombres sin sobrepeso
set_construccion <- rbind(
sample_n(muestra %>% filter(EN == 1), 30),
sample_n(muestra %>% filter(EN == 0), 30)
)
# Se saca la muestra restante tomando a la "muestra global" y a la
# submuestra, restándose
set_evaluacion <- setdiff(muestra, set_construccion)
# Primer modelo
modelo_logistico <- glm(EN ~ Navel.Girth,
family = binomial(link = "logit"), data = set_construccion)
modeloTest <- add1(modelo_logistico, scope = .~. + Bitrochanteric.diameter + Elbows.diameter +
Wrists.diameter + Knees.diameter + Waist.Girth + Hip.Girth + Knee.Girth + Ankle.Minimum.Girth)
modeloTest
desviacion <- -2*logLik(modelo_logistico)
cat("La desviación es de: ", desviacion)
# k = número de predictores
# n = tamaño de muestra
k <- length(coef(modelo_logistico))
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
# Resumen del modelo
summary(modelo_logistico)
# 6. Usando herramientas estándares1 para la exploración de modelos del entorno
# R, buscar entre dos y cinco predictores de entre las variables seleccionadas
# al azar, recordadas en el punto 3, para agregar al modelo obtenido en el paso 5.
modelo_logistico_2 <- update(modelo_logistico, .~. + Waist.Girth)
desviacion <- -2*logLik(modelo_logistico_2)
cat("La desviación es de: ", desviacion)
# k = número de predictores
# n = tamaño de muestra
k <- length(coef(modelo_logistico_2))
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
modeloTest <- add1(modelo_logistico_2, scope = .~. + Bitrochanteric.diameter + Elbows.diameter +
Wrists.diameter + Knees.diameter + Hip.Girth + Knee.Girth + Ankle.Minimum.Girth)
modelo_logistico_3 <- update(modelo_logistico_2, .~. + Bitrochanteric.diameter)
desviacion <- -2*logLik(modelo_logistico_3)
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
modeloTest <- add1(modelo_logistico_3, scope = .~. + Elbows.diameter +
Wrists.diameter + Knees.diameter + Hip.Girth + Knee.Girth + Ankle.Minimum.Girth)
# 7. Evaluar la confiabilidad de los modelos (i.e. que tengan un buen nivel de
# ajuste y son generalizables) y “arreglarlos” en caso de que tengan algún problema.
desviacion <- -2*logLik(modelo_logistico_3)
cat("La desviación es de: ", desviacion)
# k = número de predictores
# n = tamaño de muestra
k <- length(coef(modelo_logistico_3))
n <- nrow(set_construccion)
cat("La cantidad de predictores es de: ", k)
cat("El tamaño de la muestra es de: ", n)
AIC <- desviacion+2*k
BIC <- desviacion+2*k*log(n)
cat("Valor de AIC: ", AIC)
cat("Valor de BIC: ", BIC)
cat("Evaluación del modelo a partir del conjunto de entrenamiento:\n")
probs_e <- predict(modelo_logistico_3, set_evaluacion, type = "response")
umbral <- 0.5
preds_e <- ifelse(probs_e > umbral, 1, 0)
ROC_e <- roc(set_evaluacion[["EN"]], probs_e)
plot(ROC_e)
matriz_confusion <- table(Predicciones = preds_e, Real = set_evaluacion$EN)
sensibilidad <- matriz_confusion[2, 2] / sum(matriz_confusion[2, ])
especificidad <- matriz_confusion[1, 1] / sum(matriz_confusion[1, ])
matriz_confusion <- table(Predicciones = preds_e, Real = set_evaluacion$EN)
matriz_confusion
plot(ROC_e)
preds_e <- ifelse(probs_e > umbral, 1, 0)
preds_e
probs_e
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(car)
library(pROC)
library(dplyr)
library(ggplot2)
library(car)
library(pROC)
datos <- read.csv2("EP09 Datos.csv")
datos$IMC <- NULL
datos[["IMC"]] <- (datos$Weight / (datos$Height/100)^2)
datos$EN <- NULL
datos[["EN"]] <- factor(ifelse(datos$IMC >= 25, "sobrepeso", "no sobrepeso"))
hombres <- filter(datos, Gender == 1)
con <- filter(hombres, EN == "sobrepeso")
sin <- filter(hombres, EN == "no sobrepeso")
set.seed(2043)
muestraA <- con[sample(nrow(con), 45), ]
muestraB <- sin[sample(nrow(sin), 45), ]
muestra <- rbind(muestraA, muestraB)
conM <- filter(muestra, EN == "sobrepeso")
sinM <- filter(muestra, EN == "no sobrepeso")
entrenamientoA <- conM[sample(nrow(conM), 30), ]
pruebaA <- conM[!rownames(conM) %in% rownames(entrenamientoA), ]
entrenamientoB <- sinM[sample(nrow(sinM), 30), ]
pruebaB <- sinM[!rownames(sinM) %in% rownames(entrenamientoB), ]
entrenamiento <- rbind(entrenamientoA, entrenamientoB)
entrenamiento <- entrenamiento[sample(nrow(entrenamiento)), ]
prueba <- rbind(pruebaA, pruebaB)
prueba <- prueba[sample(nrow(prueba)), ]
predictores <- c(19, 22, 5, 6, 10, 11, 3, 21)
variables_seleccionadas <- colnames(muestra[-predictores])
# Crear un gráfico de cajas para cada variable seleccionada
for (var in variables_seleccionadas) {
p <- ggplot(muestra, aes_string(x = "EN", y = var)) +
geom_boxplot() +
labs(title = paste("Boxplot of", var, "by EN"))
print(p)
}
entrenamiento2 <- entrenamiento[predictores]
entrenamiento2$EN <- entrenamiento$EN
entrenamiento2$Weight <- entrenamiento$Weight
entrenamiento2$EN <- factor(entrenamiento2$EN)
modelo <- glm(EN ~ Weight, family = binomial(link = "logit"), data = entrenamiento2)
summary(modelo)
nulo <- glm(EN ~ 1, family = binomial(link = "logit"), data = entrenamiento2)
completo <- glm(EN ~ ., family = binomial(link="logit"), data = entrenamiento2)
summary(completo)
# modelo con predictores seleccionados por p-value
mejorado <- step(completo, scope = list(lower = modelo), direction = "backward", trace = 0)
summary(mejorado)
# Relacion lineal de los predictores con al variable de respuesta si existe
# Multicolinealidad
vifs <- vif(mejorado)
vifs
mean(vifs)
########________________________
anova(mejorado, test = "LRT")
########________________________
# Independencia de los residuos
durbinWatsonTest(mejorado, max.lag = 1)
# p-value superior a 0.05, entonces existe independencia de los residuos
# Evaluacion en conjunto de entrenamiento
umbral <- 0.5
probs_e <- predict(mejorado, entrenamiento, type = "response")
probs_e
ROC_e <- roc(entrenamiento[["EN"]], probs_e)
plot(ROC_e)
# resultado agradable a la vista, baja probabilidad de error tipo 1 y 2
# metodo manual de calculo sens y espe
preds_e <- sapply(probs_e, function(p) ifelse(p >= umbral, "sobrepeso", "no sobrepeso"))
preds_e <- factor(preds_e, levels = levels(datos[["EN"]]))
matriz_confusion <- table(Predicciones = preds_e, Real = entrenamiento$EN)
sensibilidad <- matriz_confusion[2, 2] / sum(matriz_confusion[2, ])
especificidad <- matriz_confusion[1, 1] / sum(matriz_confusion[1, ])
sensibilidad
especificidad
